
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A comprehensive hands-on course on Large Language Models for industry professionals">
      
      
      
        <link rel="canonical" href="https://llm-engg.github.io/slides/05_llm_implmentation/notes/">
      
      
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.21">
    
    
      
        <title>Implementing a LLM - Large Language Models - A Hands-on Approach</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.2a3383ac.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-LLD65KQHZH"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-LLD65KQHZH",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-LLD65KQHZH",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#implementing-a-llm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Large Language Models - A Hands-on Approach" class="md-header__button md-logo" aria-label="Large Language Models - A Hands-on Approach" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Large Language Models - A Hands-on Approach
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Implementing a LLM
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="deep-purple" data-md-color-accent="purple"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../schedule/" class="md-tabs__link">
        
  
  
    
  
  Schedule

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../assignments/" class="md-tabs__link">
        
  
  
    
  
  Assignments and Labs

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Large Language Models - A Hands-on Approach" class="md-nav__button md-logo" aria-label="Large Language Models - A Hands-on Approach" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Large Language Models - A Hands-on Approach
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../schedule/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Schedule
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../assignments/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignments and Labs
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#gpt-2-model" class="md-nav__link">
    <span class="md-ellipsis">
      GPT - 2 Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="GPT - 2 Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#looking-inside-the-gpt-2-model" class="md-nav__link">
    <span class="md-ellipsis">
      Looking inside the GPT-2 model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformer-block" class="md-nav__link">
    <span class="md-ellipsis">
      Transformer Block
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#layer-normalization" class="md-nav__link">
    <span class="md-ellipsis">
      Layer Normalization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#feed-forward-network-ffn" class="md-nav__link">
    <span class="md-ellipsis">
      Feed Forward Network (FFN)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#residual-connections-shortcuts" class="md-nav__link">
    <span class="md-ellipsis">
      Residual Connections / shortcuts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#illustrated-gpt-2-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      Illustrated GPT-2 Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generating-text" class="md-nav__link">
    <span class="md-ellipsis">
      Generating Text
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretraining-the-llm" class="md-nav__link">
    <span class="md-ellipsis">
      Pretraining the LLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretraining the LLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tidbits" class="md-nav__link">
    <span class="md-ellipsis">
      Tidbits
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="implementing-a-llm">Implementing a LLM</h1>
<ul>
<li>In previous classes we have covered tokenization, embeddings, and the transformer architecture in detail.</li>
<li>
<p>We have also implemented the multi head self-attention mechanism, the crucial component of transformers.</p>
</li>
<li>
<p>In this class we will put everything together and implement a small LLM from scratch using PyTorch.</p>
</li>
<li>
<p>The implmentation closely follows the GPT-2 architecture.</p>
</li>
</ul>
<h2 id="gpt-2-model">GPT - 2 Model</h2>
<p>GPT-2 model is built using the transformer decoder blocks.
The model is just a stack of transformer decoder blocks, with an embedding layer at the input and a linear + softmax layer at the output.</p>
<p>How many layers of transformer blocks?
 - GPT-2 Small: 12 layers
 - GPT-2 Medium: 24 layers
 - GPT-2 Large: 36 layers
 - GPT-2 XL: 48 layers</p>
<p>Generation Viz 1:</p>
<p><img alt="" src="https://jalammar.github.io/images/xlnet/gpt-2-output.gif" /></p>
<p>Generation Viz 2:
<img alt="" src="https://jalammar.github.io/images/xlnet/gpt-2-autoregression-2.gif" /></p>
<h3 id="looking-inside-the-gpt-2-model">Looking inside the GPT-2 model</h3>
<ul>
<li>A stack of transformer blocks</li>
<li>Each block has multi-head self-attention, feed forward network, layer normalization, and residual connections</li>
<li>Input embeddings + positional encodings at the bottom, linear + softmax layer at the top</li>
</ul>
<p><img alt="alt text" src="https://jalammar.github.io/images/gpt2/gpt-2-layers-2.png" /></p>
<p>Sample Text generation</p>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/gpt-2-simple-output-3.gif" />
- Initally the model only has one input token, so that path would be the only active one. 
- The token is processed successively through all the layers, then a vector is produced along that path. That vector can be scored against the model’s vocabulary (all the words the model knows, 50,000 words in the case of GPT-2) and the most likely next token can be selected.
- next step, we add the output from the first step to our input sequence, and have the model make its next prediction:
- Each layer of GPT-2 has retained its own interpretation of the first token and will use it in processing the second token (we’ll get into more detail about this in the following section about self-attention). GPT-2 does not re-interpret the first token in light of the second token.</p>
<p><strong>Input Encoding</strong>
- We need to give the model input in the form of token IDs.
- for each token ID, we look up its corresponding embedding vector from the embedding matrix.</p>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/gpt2-token-embeddings-wte-2.png" /></p>
<ul>
<li>We take mbeddings and add positional encodings to them to give the model information about the position of each token in the sequence.</li>
</ul>
<p><img alt="positional encoding" src="https://jalammar.github.io/images/gpt2/gpt2-positional-encoding.png" /></p>
<p>After combination: 
<img alt="Input + position encoding" src="https://jalammar.github.io/images/gpt2/gpt2-input-embedding-positional-encoding-3.png" /></p>
<p>In summary, the input to GPT-2 is a sequence of token IDs, which are converted to embedding vectors and combined with positional encodings to form the final input representation for the model.</p>
<p><strong>Passing token through the transformer blocks</strong>
- The first block can now process the token by first passing it through the self-attention process, then passing it through its neural network layer. 
- Once the first transformer block processes the token, it sends its resulting vector up the stack to be processed by the next block. 
- The process is identical in each block, but each block has its own weights in both self-attention and the neural network sublayers.
<img alt="alt text" src="https://jalammar.github.io/images/gpt2/gpt2-transformer-block-vectors-2.png" /></p>
<p><strong>Self-Attention in GPT-2</strong>
- Self attention allows each token to pay importance to other tokens in the sequence when processing itself.
- Example 1: ”The animal didn't cross the street because it was too tired” . When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.
- Example 2 : "A robot must obey the orders given <strong>it</strong> by human beings except where <strong>such orders</strong> would conflict with <strong>the First Law.</strong>” Here, self-attention helps the model understand that "such orders" refers to "the orders given it by human beings".</p>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/gpt2-self-attention-example-2.png" /></p>
<p><strong>Self-Attention Process</strong>
- For each token, we create Query (Q), Key (K), and Value (V) vectors
- Query: The query is a representation of the current word used to score against all the other words (using their keys). We only care about the query of the token we’re currently processing.
- Key: Key vectors are like labels for all the words in the segment. They’re what we match against in our search for relevant words.
- Value: Value vectors are actual word representations, once we’ve scored how relevant each word is, these are the values we add up to represent the current word.</p>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/self-attention-example-folders-scores-3.png" />
- We compute attention scores by taking the dot product of the Query vector of the current token with the Key vectors of all tokens.
- We scale the scores by dividing by the square root of the dimension of the Key vectors.
- We apply softmax to the scores to get attention weights.
- We multiply each Value vector by its corresponding attention weight.
- We sum the weighted Value vectors to get the output vector for the current token.</p>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/gpt2-value-vector-sum.png" /></p>
<p><strong>Model Output</strong>
 - After the input token has passed through all the transformer blocks, we get a final output vector. 
 <img alt="" src="https://jalammar.github.io/images/gpt2/gpt2-output-projection-2.png" /></p>
<ul>
<li>This vector is then passed through a linear layer followed by a softmax layer to produce the final output probabilities for each token in the vocabulary.</li>
</ul>
<p><img alt="" src="https://jalammar.github.io/images/gpt2/gpt2-output.png" /></p>
<p><img alt="alt text" src="01_llm_arch.png" /></p>
<p>Our imlementations:
vocabulary size: 50257 (same as GPT-2)
embedding dimension: 768
number of transformer blocks: 12
number of attention heads: 12
maximum sequence length: 1024</p>
<h2 id="transformer-block">Transformer Block</h2>
<h2 id="layer-normalization">Layer Normalization</h2>
<h2 id="feed-forward-network-ffn">Feed Forward Network (FFN)</h2>
<h2 id="residual-connections-shortcuts">Residual Connections / shortcuts</h2>
<h2 id="illustrated-gpt-2-architecture">Illustrated GPT-2 Architecture</h2>
<h2 id="generating-text">Generating Text</h2>
<p>as we can see, the transformer Block maintains the input dimensions in its output, indicating that the transformer architecturfe proc esses sequences of data without altering their shape through out the network</p>
<h2 id="pretraining-the-llm">Pretraining the LLM</h2>
<h3 id="tidbits">Tidbits</h3>
<ul>
<li>
<p>show cross entropy loss calculation for next token prediction</p>
<ul>
<li>on random token predction on the vocabulary</li>
<li>show as model trains </li>
<li>show on trained weights</li>
</ul>
</li>
<li></li>
</ul>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.highlight", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
    
  </body>
</html>